#!/usr/bin/env python3
"""
ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ë¶„í•  OCR ì‹œìŠ¤í…œ (ìˆ˜ì •ëœ ë²„ì „)
ë¬´ì‘ì • ìë¥´ì§€ ì•Šê³  AIê°€ ë¨¼ì € ì›í˜• ìœ„ì¹˜ë¥¼ ì°¾ì€ í›„ í•´ë‹¹ ì˜ì—­ë§Œ ì„¸ë°€ ì²˜ë¦¬
"""

import os
import sys
sys.path.append('src')

class SmartRegionOCR:
    """ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ê¸°ë°˜ OCR ì²˜ë¦¬ê¸°"""
    
    def __init__(self, api_key, model_name="qwen-vl-plus"):
        self.api_key = api_key
        self.model_name = model_name
        
    def find_circle_regions_with_ai(self, image_path):
        """AIë¡œ ë¨¼ì € ì›í˜•ì´ ìˆëŠ” ëŒ€ëµì ì¸ ìœ„ì¹˜ ì°¾ê¸°"""
        try:
            from cloud_ocr import CloudOCRProcessor
            
            processor = CloudOCRProcessor(self.api_key, self.model_name)
            
            # 1ë‹¨ê³„: ì „ì²´ ì´ë¯¸ì§€ì—ì„œ ì›í˜• ìœ„ì¹˜ ìŠ¤ìº”
            location_prompt = """ì´ ì´ë¯¸ì§€ì—ì„œ ìˆ˜ê¸°ë¡œ ê·¸ì–´ì§„ ì›í˜•ì´ë‚˜ íƒ€ì›í˜• ë„í˜•ë“¤ì´ ìˆëŠ” ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.

ğŸ¯ ì°¾ì•„ì•¼ í•  ê²ƒ:
- ì†ìœ¼ë¡œ ê·¸ë¦° ì›, íƒ€ì›, ë™ê·¸ë¼ë¯¸ ìœ„ì¹˜
- ì™„ì „í•˜ì§€ ì•Šì€ ì›í˜•ë„ í¬í•¨

ğŸ“ ì¶œë ¥ í˜•ì‹:
ì›í˜•ì´ ìˆëŠ” ìœ„ì¹˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•´ì£¼ì„¸ìš”:
- "ì¢Œìƒë‹¨ì— ì›í˜• 2ê°œ"
- "ì¤‘ì•™ ë¶€ë¶„ì— í° ì›í˜• 1ê°œ"  
- "ìš°í•˜ë‹¨ì— ì‘ì€ ì›í˜•ë“¤ ì—¬ëŸ¬ ê°œ"
- "ì „ì²´ì ìœ¼ë¡œ ë¶„ì‚°ë˜ì–´ ìˆìŒ"

ìœ„ì¹˜ê°€ íŒŒì•…ë˜ë©´ ê·¸ ì˜ì—­ë“¤ì„ ì–´ë–»ê²Œ ë‚˜ëˆ„ë©´ ì¢‹ì„ì§€ë„ ì œì•ˆí•´ì£¼ì„¸ìš”."""

            # ê¸°ì¡´ CloudOCRProcessorì˜ ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‚¬ìš©
            import base64
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            messages = [
                {
                    "role": "user", 
                    "content": [
                        {"image": f"data:image/jpeg;base64,{base64_image}"},
                        {"text": location_prompt}
                    ]
                }
            ]
            
            import dashscope
            dashscope.api_key = self.api_key
            
            response = dashscope.MultiModalConversation.call(
                model=self.model_name,
                messages=messages
            )
            
            if response and response.status_code == 200:
                content = response.output.choices[0].message.content
                if isinstance(content, list):
                    location_info = ' '.join([item.get('text', '') for item in content if item.get('text')])
                else:
                    location_info = str(content)
                
                print(f"ğŸ” AIê°€ ë¶„ì„í•œ ì›í˜• ìœ„ì¹˜:")
                print(f"   {location_info}")
                
                return location_info
            else:
                return "ë¶„ì„ ì‹¤íŒ¨"
                
        except Exception as e:
            print(f"âŒ ìœ„ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "ë¶„ì„ ì‹¤íŒ¨"
    
    def create_smart_regions(self, image_path, location_info):
        """AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸í•œ ì˜ì—­ ë¶„í• """
        try:
            from PIL import Image
            
            img = Image.open(image_path)
            width, height = img.size
            
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {width}Ã—{height}")
            
            # ìœ„ì¹˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ì—­ ê²°ì •
            regions = []
            
            if "ì „ì²´ì ìœ¼ë¡œ ë¶„ì‚°" in location_info or "ì—¬ëŸ¬ ê³³" in location_info:
                # ì „ì²´ ë¶„ì‚° â†’ 3Ã—3 ê·¸ë¦¬ë“œ (ì˜¤ë²„ë© í¬í•¨)
                print("ğŸ“Š ì „ì²´ ë¶„ì‚° ê°ì§€ â†’ 3Ã—3 ì˜¤ë²„ë© ê·¸ë¦¬ë“œ ì‚¬ìš©")
                regions = self._create_overlap_grid(width, height, 3, 3)
                
            elif "ì¢Œ" in location_info and "ìš°" in location_info:
                # ì¢Œìš° ë¶„í¬ â†’ 2Ã—2 ê·¸ë¦¬ë“œ
                print("ğŸ“Š ì¢Œìš° ë¶„í¬ ê°ì§€ â†’ 2Ã—2 ê·¸ë¦¬ë“œ ì‚¬ìš©")
                regions = self._create_overlap_grid(width, height, 2, 2)
                
            elif "ìƒë‹¨" in location_info and "í•˜ë‹¨" in location_info:
                # ìƒí•˜ ë¶„í¬ â†’ 2Ã—3 ê·¸ë¦¬ë“œ
                print("ğŸ“Š ìƒí•˜ ë¶„í¬ ê°ì§€ â†’ 2Ã—3 ê·¸ë¦¬ë“œ ì‚¬ìš©")
                regions = self._create_overlap_grid(width, height, 3, 2)
                
            elif "ì¤‘ì•™" in location_info:
                # ì¤‘ì•™ ì§‘ì¤‘ â†’ ì¤‘ì•™ ê°•í™” ë°©ì‹
                print("ğŸ“Š ì¤‘ì•™ ì§‘ì¤‘ ê°ì§€ â†’ ì¤‘ì•™ ê°•í™” ì˜ì—­ ì‚¬ìš©")
                regions = self._create_center_focused_regions(width, height)
                
            else:
                # ê¸°ë³¸ê°’ â†’ 2Ã—2 ê·¸ë¦¬ë“œ
                print("ğŸ“Š ê¸°ë³¸ ì„¤ì • â†’ 2Ã—2 ê·¸ë¦¬ë“œ ì‚¬ìš©")
                regions = self._create_overlap_grid(width, height, 2, 2)
            
            print(f"ğŸ”² ìƒì„±ëœ ì˜ì—­ ìˆ˜: {len(regions)}ê°œ")
            return regions
            
        except Exception as e:
            print(f"âŒ ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _create_overlap_grid(self, width, height, cols, rows, overlap=0.2):
        """ì˜¤ë²„ë©ì´ ìˆëŠ” ê·¸ë¦¬ë“œ ìƒì„±"""
        regions = []
        
        grid_width = width // cols
        grid_height = height // rows
        overlap_w = int(grid_width * overlap)
        overlap_h = int(grid_height * overlap)
        
        for row in range(rows):
            for col in range(cols):
                x1 = max(0, col * grid_width - overlap_w)
                y1 = max(0, row * grid_height - overlap_h)
                x2 = min(width, (col + 1) * grid_width + overlap_w)
                y2 = min(height, (row + 1) * grid_height + overlap_h)
                
                regions.append({
                    'bbox': (x1, y1, x2, y2),
                    'name': f"ê·¸ë¦¬ë“œ_{row}_{col}",
                    'priority': 1
                })
        
        return regions
    
    def _create_center_focused_regions(self, width, height):
        """ì¤‘ì•™ ê°•í™” ì˜ì—­ ìƒì„±"""
        regions = []
        
        # ì¤‘ì•™ ì˜ì—­ (í° ì˜ì—­)
        center_w = width * 0.6
        center_h = height * 0.6
        center_x = (width - center_w) // 2
        center_y = (height - center_h) // 2
        
        regions.append({
            'bbox': (int(center_x), int(center_y), int(center_x + center_w), int(center_y + center_h)),
            'name': "ì¤‘ì•™_ë©”ì¸",
            'priority': 1
        })
        
        # ì½”ë„ˆ ì˜ì—­ë“¤
        corner_size = 0.4
        corners = [
            (0, 0, width * corner_size, height * corner_size, "ì¢Œìƒë‹¨"),
            (width * (1-corner_size), 0, width, height * corner_size, "ìš°ìƒë‹¨"),
            (0, height * (1-corner_size), width * corner_size, height, "ì¢Œí•˜ë‹¨"),
            (width * (1-corner_size), height * (1-corner_size), width, height, "ìš°í•˜ë‹¨")
        ]
        
        for x1, y1, x2, y2, name in corners:
            regions.append({
                'bbox': (int(x1), int(y1), int(x2), int(y2)),
                'name': name,
                'priority': 2
            })
        
        return regions
    
    def process_smart_regions(self, image_path):
        """ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        print(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR ì‹œì‘: {os.path.basename(image_path)}")
        
        # 1ë‹¨ê³„: AIë¡œ ì›í˜• ìœ„ì¹˜ ë¶„ì„
        location_info = self.find_circle_regions_with_ai(image_path)
        
        # 2ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ì—­ ìƒì„±
        regions = self.create_smart_regions(image_path, location_info)
        
        if not regions:
            print("âŒ ì˜ì—­ ìƒì„± ì‹¤íŒ¨")
            return None
        
        # 3ë‹¨ê³„: ê° ì˜ì—­ ì²˜ë¦¬
        from PIL import Image
        from cloud_ocr import CloudOCRProcessor
        
        img = Image.open(image_path)
        processor = CloudOCRProcessor(self.api_key, self.model_name)
        
        all_results = []
        successful_regions = 0
        
        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì²˜ë¦¬
        regions.sort(key=lambda x: x['priority'])
        
        for i, region in enumerate(regions):
            x1, y1, x2, y2 = region['bbox']
            name = region['name']
            
            print(f"ğŸ¤– {name} ì˜ì—­ ì²˜ë¦¬ ì¤‘... ({x1},{y1})â†’({x2},{y2})")
            
            try:
                # ì˜ì—­ í¬ë¡­
                cropped = img.crop((x1, y1, x2, y2))
                
                # ì„ì‹œ ì €ì¥
                os.makedirs("output/smart_regions", exist_ok=True)
                temp_path = f"output/smart_regions/{name}.png"
                cropped.save(temp_path)
                
                # AI ì²˜ë¦¬ - process_image ëŒ€ì‹  ì§ì ‘ ì²˜ë¦¬í•˜ì—¬ tuple ë¬¸ì œ í•´ê²°
                result = self._process_region_directly(temp_path, processor)
                
                if result and len(result.strip()) > 5:
                    # ì¤‘ë³µ ì œê±° (ì´ì „ ê²°ê³¼ì™€ ë¹„êµ)
                    if not any(result.strip() in existing for existing in all_results):
                        all_results.append(result.strip())
                        successful_regions += 1
                        print(f"âœ… {name}: '{result.strip()[:30]}...'")
                    else:
                        print(f"ğŸ”„ {name}: ì¤‘ë³µ ê²°ê³¼ ì œì™¸")
                else:
                    print(f"âŒ {name}: í…ìŠ¤íŠ¸ ì—†ìŒ")
                    
            except Exception as e:
                print(f"âŒ {name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ê³¼ í†µí•©
        if all_results:
            final_result = "\n".join(all_results)
            
            print(f"\nğŸ‰ ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ì²˜ë¦¬ ì™„ë£Œ:")
            print(f"   ì„±ê³µ ì˜ì—­: {successful_regions}/{len(regions)}ê°œ")
            print(f"   ê³ ìœ  í…ìŠ¤íŠ¸: {len(all_results)}ê°œ")
            print(f"   ì´ ê¸¸ì´: {len(final_result)}ì")
            
            return final_result
        else:
            print(f"\nâš ï¸  ëª¨ë“  ì˜ì—­ì—ì„œ ì›í˜• í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            return None

    def _process_region_directly(self, image_path, processor):
        """ì˜ì—­ì„ ì§ì ‘ ì²˜ë¦¬í•˜ì—¬ tuple ë¬¸ì œ í•´ê²°"""
        try:
            import base64
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            # ì›í˜•/íƒ€ì›í˜• ê°ì§€ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸
            prompt_text = """ì´ ì´ë¯¸ì§€ ì˜ì—­ì—ì„œ ìˆ˜ê¸°ë¡œ ê·¸ì–´ì§„ ì›í˜•ì´ë‚˜ íƒ€ì›í˜• ë„í˜• ì•ˆì— ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì°¾ì•„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ğŸ¯ ì°¾ì•„ì•¼ í•  ê²ƒ:
- ì†ìœ¼ë¡œ ê·¸ë¦° ì›, íƒ€ì›, ë™ê·¸ë¼ë¯¸ ì•ˆì˜ í…ìŠ¤íŠ¸
- ì™„ì „í•˜ì§€ ì•Šì€ ì›í˜•ë„ í¬í•¨ (ì°Œê·¸ëŸ¬ì§„ ì›, íƒ€ì›)
- ì‘ì€ ì›ë¶€í„° í° ì›ê¹Œì§€ ëª¨ë“  í¬ê¸°
- ì†ê¸€ì”¨ë‚˜ ì¸ì‡„ í…ìŠ¤íŠ¸ ëª¨ë‘

âš ï¸ ë¬´ì‹œí•  ê²ƒ:
- ì‚¬ê°í˜•, ì‚¼ê°í˜•, ì§ì„ ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í…ìŠ¤íŠ¸
- ì›í˜• ë°–ì— ìˆëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸
- í‘œë‚˜ ì„ ìœ¼ë¡œë§Œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸

ğŸ“ ì¶œë ¥ í˜•ì‹:
ì›í˜•/íƒ€ì›í˜• ì•ˆì— í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ í…ìŠ¤íŠ¸ë§Œ í•œ ì¤„ì”© ì¶œë ¥í•˜ê³ ,
ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³  ì¶œë ¥í•´ì£¼ì„¸ìš”.

Find text inside hand-drawn circles or ellipses only. Ignore rectangular boxes and plain text."""
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"image": f"data:image/png;base64,{base64_image}"},
                        {"text": prompt_text}
                    ]
                }
            ]
            
            import dashscope
            response = dashscope.MultiModalConversation.call(
                model=processor.model_name,
                messages=messages
            )
            
            # ì‘ë‹µ ì²˜ë¦¬ - response_utils ì‚¬ìš©
            from response_utils import extract_text_from_response
            result = extract_text_from_response(response)
            
            # ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸ (tuple ë°©ì§€)
            if isinstance(result, tuple):
                result = result[0] if len(result) > 0 else "ì²˜ë¦¬ ì‹¤íŒ¨"
            
            return result if result else "ì—†ìŒ"
            
        except Exception as e:
            print(f"âŒ ì˜ì—­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"


def test_smart_region_ocr():
    """ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)")
    print("=" * 60)
    
    try:
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv('QWEN_API_KEY')
        
        if not api_key or api_key == "your_api_key_here":
            print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return False
        
        test_image = "input/17301.png"
        
        if not os.path.exists(test_image):
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì—†ìŒ: {test_image}")
            return False
        
        # ìŠ¤ë§ˆíŠ¸ OCR ì‹¤í–‰
        smart_ocr = SmartRegionOCR(api_key, "qwen-vl-plus")
        result = smart_ocr.process_smart_regions(test_image)
        
        if result:
            # ê²°ê³¼ ì €ì¥
            os.makedirs("output", exist_ok=True)
            result_path = "output/smart_region_result_fixed.txt"
            with open(result_path, 'w', encoding='utf-8') as f:
                f.write("=== ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR ê²°ê³¼ (ìˆ˜ì •ëœ ë²„ì „) ===\n")
                f.write(f"ë°©ì‹: AI ìœ„ì¹˜ ë¶„ì„ â†’ ì ì‘ì  ì˜ì—­ ë¶„í•  â†’ ì„¸ë°€ ì²˜ë¦¬\n")
                f.write(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result)}ì\n\n")
                f.write("=== ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ===\n")
                f.write(result)
            
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {result_path}")
            
            # ë¯¸ë¦¬ë³´ê¸°
            print(f"\nğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:")
            lines = result.split('\n')
            for i, line in enumerate(lines):
                print(f"  {i+1}: {line}")
            
            return True
        else:
            print("âŒ ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ìŠ¤ë§ˆíŠ¸ ì˜ì—­ ë¶„í•  OCR ì‹œìŠ¤í…œ (ìˆ˜ì •ëœ ë²„ì „)")
    print("ğŸ’¡ ì•„ì´ë””ì–´: AIê°€ ë¨¼ì € ì›í˜• ìœ„ì¹˜ íŒŒì•… â†’ ì ì‘ì  ì˜ì—­ ë¶„í• ")
    print("ğŸ”§ ìˆ˜ì • ì‚¬í•­: tuple ë°˜í™˜ ê°’ ë¬¸ì œ í•´ê²°")
    print("=" * 60)
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
    if os.path.basename(os.getcwd()) != "test-sdp":
        if os.path.exists("test-sdp"):
            os.chdir("test-sdp")
        else:
            print("âŒ test-sdp ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    success = test_smart_region_ocr()
    
    if success:
        print(f"\n" + "=" * 60)
        print("ğŸ‰ ìŠ¤ë§ˆíŠ¸ ì˜ì—­ OCR ì„±ê³µ!")
        print("âœ¨ ì¥ì :")
        print("   âœ… ë¬´ì‘ì • ìë¥´ì§€ ì•ŠìŒ")
        print("   âœ… AIê°€ ë¨¼ì € ìœ„ì¹˜ íŒŒì•…")
        print("   âœ… ì ì‘ì  ì˜ì—­ ë¶„í• ")
        print("   âœ… ì¤‘ë³µ ì œê±°")
        print("   âœ… ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬")
        print("   âœ… tuple ì˜¤ë¥˜ ìˆ˜ì •")
        
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print("   output/smart_regions/ - ê° ì˜ì—­ë³„ ì´ë¯¸ì§€")
        print("   output/smart_region_result_fixed.txt - ìµœì¢… ê²°ê³¼")
        
    else:
        print(f"\nğŸ’¡ ê°œì„  ë°©í–¥:")
        print("   1. ìœ„ì¹˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ê°œì„ ")
        print("   2. ì˜ì—­ ë¶„í•  ì•Œê³ ë¦¬ì¦˜ ì¡°ì •")
        print("   3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸")

if __name__ == "__main__":
    main()
