"""
í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë§¤í•‘ ë° ì‹œê°í™” ë„êµ¬
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import json
import os
import re
from datetime import datetime
from typing import List, Dict, Tuple, Optional

def get_text_coordinates_from_api(api_key, model_name, image_path):
    """
    APIì—ì„œ í…ìŠ¤íŠ¸ì™€ ì¢Œí‘œ ì •ë³´ë¥¼ í•¨ê»˜ ìš”ì²­
    """
    try:
        import dashscope
        import base64
        from endpoint_config import configure_international_endpoint
        
        # êµ­ì œ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        configure_international_endpoint()
        dashscope.api_key = api_key
        
        # ì´ë¯¸ì§€ ì¸ì½”ë”©
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ì¢Œí‘œ ì •ë³´ë¥¼ í¬í•¨í•œ ìš”ì²­
        messages = [
            {
                "role": "user",
                "content": [
                    {"image": f"data:image/jpeg;base64,{base64_image}"},
                    {"text": "ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ê° í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜(ìƒë‹¨/ì¤‘ë‹¨/í•˜ë‹¨, ì¢Œì¸¡/ì¤‘ì•™/ìš°ì¸¡)ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”. í˜•ì‹: [í…ìŠ¤íŠ¸] - ìœ„ì¹˜: [ìœ„ì¹˜ì •ë³´]"}
                ]
            }
        ]
        
        response = dashscope.MultiModalConversation.call(
            model=model_name,
            messages=messages
        )
        
        from response_utils import extract_text_from_response
        result = extract_text_from_response(response)
        
        return result
        
    except Exception as e:
        print(f"âŒ ì¢Œí‘œ ì •ë³´ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

def estimate_text_regions(image_path, extracted_text):
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì¶”ì •
    """
    try:
        # OpenCVë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            return None
        
        height, width = image.shape[:2]
        
        # í…ìŠ¤íŠ¸ë¥¼ ë¼ì¸ë³„ë¡œ ë¶„í• 
        lines = [line.strip() for line in extracted_text.split('\n') if line.strip()]
        
        # ê° ë¼ì¸ì— ëŒ€í•´ ëŒ€ëµì ì¸ ìœ„ì¹˜ ì¶”ì •
        regions = []
        line_height = height // max(len(lines), 1)
        
        for i, line in enumerate(lines):
            # ìˆ˜ì§ ìœ„ì¹˜ ê³„ì‚°
            y_start = i * line_height
            y_end = min((i + 1) * line_height, height)
            
            # ìˆ˜í‰ ìœ„ì¹˜ëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì¶”ì •
            text_width = min(len(line) * 10, width - 40)  # ëŒ€ëµì ì¸ ì¶”ì •
            x_start = 20
            x_end = x_start + text_width
            
            regions.append({
                'text': line,
                'bbox': (x_start, y_start, x_end, y_end),
                'confidence': 0.8  # ì¶”ì •ê°’ì´ë¯€ë¡œ ë‚®ì€ ì‹ ë¢°ë„
            })
        
        return regions
        
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì • ì‹¤íŒ¨: {e}")
        return None

def use_easyocr_for_coordinates(image_path):
    """
    EasyOCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ
    """
    try:
        import easyocr
        
        # EasyOCR ë¦¬ë” ì´ˆê¸°í™” (í•œêµ­ì–´, ì˜ì–´)
        reader = easyocr.Reader(['ko', 'en'], gpu=True)
        
        # í…ìŠ¤íŠ¸ ì¸ì‹
        results = reader.readtext(image_path)
        
        # ê²°ê³¼ íŒŒì‹±
        text_regions = []
        full_text_parts = []
        
        for (bbox, text, confidence) in results:
            # bboxëŠ” 4ê°œ ì ì˜ ì¢Œí‘œ [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]
            # ì´ë¥¼ (x_min, y_min, x_max, y_max) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            x_coords = [point[0] for point in bbox]
            y_coords = [point[1] for point in bbox]
            
            x_min, x_max = int(min(x_coords)), int(max(x_coords))
            y_min, y_max = int(min(y_coords)), int(max(y_coords))
            
            text_regions.append({
                'text': text,
                'bbox': (x_min, y_min, x_max, y_max),
                'confidence': confidence,
                'original_bbox': bbox
            })
            
            full_text_parts.append(text)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = '\n'.join(full_text_parts)
        
        return text_regions, full_text
        
    except ImportError:
        print("âš ï¸  EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¶”ì • ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return None, None
    except Exception as e:
        print(f"âŒ EasyOCR ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None, None

def draw_text_boxes_on_image(image_path, text_regions, output_path, method_name="OCR"):
    """
    ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ë°•ìŠ¤ì™€ ë‚´ìš©ì„ ê·¸ë ¤ì„œ ì €ì¥
    """
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return False
        
        # PILë¡œ ë³€í™˜ (í•œê¸€ í°íŠ¸ ì§€ì›)
        image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(image_pil)
        
        # í°íŠ¸ ì„¤ì •
        font_size = max(12, min(24, image.shape[1] // 50))
        try:
            # Linux/WSL
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
        except:
            try:
                # Windows
                font = ImageFont.truetype("arial.ttf", font_size)
            except:
                try:
                    # í•œê¸€ í°íŠ¸
                    font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", font_size)
                except:
                    font = ImageFont.load_default()
        
        # ìƒ‰ìƒ ì„¤ì •
        colors = [
            (255, 0, 0),    # ë¹¨ê°•
            (0, 255, 0),    # ì´ˆë¡
            (0, 0, 255),    # íŒŒë‘
            (255, 255, 0),  # ë…¸ë‘
            (255, 0, 255),  # ë§ˆì  íƒ€
            (0, 255, 255),  # ì‹œì•ˆ
            (255, 128, 0),  # ì£¼í™©
            (128, 0, 255),  # ë³´ë¼
        ]
        
        print(f"ğŸ“ {len(text_regions)}ê°œì˜ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ê·¸ë¦½ë‹ˆë‹¤...")
        
        for i, region in enumerate(text_regions):
            bbox = region['bbox']
            text = region['text']
            confidence = region.get('confidence', 0.0)
            
            x_min, y_min, x_max, y_max = bbox
            color = colors[i % len(colors)]
            
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=2)
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ë°°ê²½ìƒ‰ ì„¤ì •
            alpha = int(confidence * 100) if confidence > 0.5 else 50
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤
            text_bbox = draw.textbbox((x_min, y_min - font_size - 5), f"{i+1}", font=font)
            draw.rectangle([
                text_bbox[0] - 2, text_bbox[1] - 2,
                text_bbox[2] + 2, text_bbox[3] + 2
            ], fill=(*color, alpha))
            
            # í…ìŠ¤íŠ¸ ë²ˆí˜¸ í‘œì‹œ
            draw.text((x_min, y_min - font_size - 5), f"{i+1}", fill=(255, 255, 255), font=font)
            
            # ì‹ ë¢°ë„ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
            if confidence > 0:
                conf_text = f"{confidence:.2f}"
                draw.text((x_max - 30, y_min - font_size - 5), conf_text, fill=color, font=font)
        
        # ë²”ë¡€ ì¶”ê°€
        legend_y = 10
        draw.text((10, legend_y), f"{method_name} ê²°ê³¼ ({len(text_regions)}ê°œ ì˜ì—­)", 
                 fill=(0, 0, 0), font=font)
        
        # í…ìŠ¤íŠ¸ ëª©ë¡ ì¶”ê°€ (ì´ë¯¸ì§€ í•˜ë‹¨)
        text_list_y = image.shape[0] - (len(text_regions) + 2) * (font_size + 5)
        text_list_y = max(text_list_y, image.shape[0] // 2)  # ìµœì†Œ ì¤‘ê°„ ìœ„ì¹˜
        
        draw.text((10, text_list_y), "ì¸ì‹ëœ í…ìŠ¤íŠ¸:", fill=(0, 0, 0), font=font)
        
        for i, region in enumerate(text_regions):
            text_line = f"{i+1}. {region['text']}"
            if region.get('confidence', 0) > 0:
                text_line += f" ({region['confidence']:.2f})"
            
            y_pos = text_list_y + (i + 1) * (font_size + 5)
            color = colors[i % len(colors)]
            draw.text((20, y_pos), text_line, fill=color, font=font)
        
        # ë‹¤ì‹œ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result_image = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ì €ì¥
        success = cv2.imwrite(output_path, result_image)
        
        if success:
            print(f"âœ… í…ìŠ¤íŠ¸ ë§¤í•‘ ì´ë¯¸ì§€ ì €ì¥: {os.path.basename(output_path)}")
            return True
        else:
            print(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {output_path}")
            return False
        
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_text_coordinate_mapping(image_path, extracted_text, output_dir, method="auto"):
    """
    ë©”ì¸ í•¨ìˆ˜: í…ìŠ¤íŠ¸ ì¢Œí‘œ ë§¤í•‘ ì´ë¯¸ì§€ ìƒì„±
    """
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    
    print(f"\nğŸ¯ í…ìŠ¤íŠ¸ ì¢Œí‘œ ë§¤í•‘ ì‹œì‘: {os.path.basename(image_path)}")
    
    text_regions = None
    ocr_text = None
    method_used = "Unknown"
    
    # ë°©ë²• 1: EasyOCR ì‚¬ìš© (ê°€ì¥ ì •í™•í•¨)
    if method in ["auto", "easyocr"]:
        print("ğŸ” EasyOCRë¡œ ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ ì‹œë„...")
        text_regions, ocr_text = use_easyocr_for_coordinates(image_path)
        if text_regions:
            method_used = "EasyOCR"
            print(f"âœ… EasyOCRë¡œ {len(text_regions)}ê°œ ì˜ì—­ ê²€ì¶œ")
    
    # ë°©ë²• 2: ì¶”ì • ë°©ë²• (EasyOCR ì‹¤íŒ¨ ì‹œ ë˜ëŠ” ì§ì ‘ ì„ íƒ)
    if not text_regions:
        print("ğŸ” ì¶”ì • ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê³„ì‚°...")
        text_regions = estimate_text_regions(image_path, extracted_text)
        method_used = "ì¶”ì •ë°©ë²•"
        if text_regions:
            print(f"âœ… ì¶”ì •ìœ¼ë¡œ {len(text_regions)}ê°œ ì˜ì—­ ìƒì„±")
    
    if not text_regions:
        print("âŒ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
    output_path = os.path.join(output_dir, f"{base_name}_coordinates_{method_used.lower()}.png")
    success = draw_text_boxes_on_image(image_path, text_regions, output_path, method_used)
    
    # í…ìŠ¤íŠ¸ ë¹„êµ ì •ë³´ ì €ì¥
    if success:
        comparison_file = os.path.join(output_dir, f"{base_name}_text_comparison.txt")
        with open(comparison_file, 'w', encoding='utf-8') as f:
            f.write(f"=== í…ìŠ¤íŠ¸ ì¢Œí‘œ ë§¤í•‘ ê²°ê³¼ ===\n")
            f.write(f"ë°©ë²•: {method_used}\n")
            f.write(f"ê²€ì¶œëœ ì˜ì—­ ìˆ˜: {len(text_regions)}\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("=== ì›ë³¸ ì¶”ì¶œ í…ìŠ¤íŠ¸ ===\n")
            f.write(extracted_text)
            f.write("\n\n")
            
            if ocr_text:
                f.write("=== OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì¶œ í…ìŠ¤íŠ¸ ===\n")
                f.write(ocr_text)
                f.write("\n\n")
            
            f.write("=== ì˜ì—­ë³„ ìƒì„¸ ì •ë³´ ===\n")
            for i, region in enumerate(text_regions):
                bbox = region['bbox']
                f.write(f"{i+1}. í…ìŠ¤íŠ¸: {region['text']}\n")
                f.write(f"   ì¢Œí‘œ: ({bbox[0]}, {bbox[1]}) - ({bbox[2]}, {bbox[3]})\n")
                if region.get('confidence'):
                    f.write(f"   ì‹ ë¢°ë„: {region['confidence']:.3f}\n")
                f.write("\n")
        
        print(f"ğŸ“„ ë¹„êµ ì •ë³´ ì €ì¥: {os.path.basename(comparison_file)}")
    
    return success

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    print("ğŸ¯ í…ìŠ¤íŠ¸ ì¢Œí‘œ ë§¤í•‘ ë„êµ¬ í…ŒìŠ¤íŠ¸")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    try:
        import easyocr
        print("âœ… EasyOCR ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        print("âŒ EasyOCR ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
