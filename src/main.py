"""
ë©”ì¸ ëŒ€í™”ì‹ ì¸í„°í˜ì´ìŠ¤
"""

import os
import sys
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from models import list_local_models, list_cloud_models, get_model_info
from utils import (
    get_gpu_info, check_model_compatibility, get_image_files, 
    print_system_info, format_time
)
from local_ocr_improved import LocalOCRProcessor, get_loaded_models_info, clear_all_models, get_memory_info
from cloud_ocr import run_cloud_ocr

class OCRTestInterface:
    def __init__(self):
        self.input_dir = os.path.join(os.path.dirname(__file__), '..', 'input')
        self.output_dir = os.path.join(os.path.dirname(__file__), '..', 'output')
        self.api_key = os.getenv('QWEN_API_KEY')
        
    def show_main_menu(self):
        """ë©”ì¸ ë©”ë‰´ í‘œì‹œ"""
        print("\n" + "="*50)
        print("ğŸ” OCR ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬")
        print("="*50)
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        print_system_info()
        
        # ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
        image_files = get_image_files(self.input_dir)
        print(f"ğŸ“ ì…ë ¥ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        
        if len(image_files) == 0:
            print("âš ï¸  input í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ê²½ë¡œ: {os.path.abspath(self.input_dir)}")
            print("   ì§€ì› í˜•ì‹: jpg, jpeg, png, bmp, tiff, webp")
            return None
        
        # ë©”ë‰´ ì˜µì…˜
        print("\nğŸ“‹ ë©”ë‰´:")
        print("1. ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©")
        print("2. Qwen Cloud API ì‚¬ìš©") 
        print("3. ì„¤ì • í™•ì¸")
        print("4. ëª¨ë¸ ê´€ë¦¬ ë„êµ¬")
        print("5. ì¢…ë£Œ")
        
        while True:
            try:
                choice = input("\nì„ íƒí•˜ì„¸ìš” (1-5): ").strip()
                if choice in ['1', '2', '3', '4', '5']:
                    return choice
                else:
                    print("âŒ 1-5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return '5'
    
    def show_local_model_menu(self):
        """ë¡œì»¬ ëª¨ë¸ ì„ íƒ ë©”ë‰´"""
        print("\n" + "="*60)
        print("ğŸ–¥ï¸  ë¡œì»¬ ëª¨ë¸ ì„ íƒ")
        print("="*60)
        
        # GPU ì •ë³´ í‘œì‹œ
        gpu_name, total_memory, available_memory = get_gpu_info()
        if gpu_name:
            print(f"ğŸ® GPU: {gpu_name}")
            print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {total_memory:.1f}GB (ì‚¬ìš©ê°€ëŠ¥: {available_memory:.1f}GB)")
        else:
            print("âš ï¸  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        
        print()
        
        # ëª¨ë¸ ëª©ë¡ í‘œì‹œ
        models = list_local_models()
        model_keys = list(models.keys())
        
        for i, (key, info) in enumerate(models.items(), 1):
            print(f"{i}. {info['name']}")
            print(f"   ğŸ“Š íŒŒë¼ë¯¸í„°: {info['params']}")
            print(f"   ğŸ’¾ ìµœì†Œ GPU ë©”ëª¨ë¦¬: {info['min_gpu_memory']}GB | ê¶Œì¥: {info['recommended_gpu_memory']}GB")
            
            # í˜¸í™˜ì„± ì²´í¬
            compatible, message = check_model_compatibility(info)
            if compatible:
                if "ìµœì " in message:
                    print(f"   âœ… {message}")
                else:
                    print(f"   âš ï¸  {message}")
            else:
                print(f"   âŒ {message}")
            
            print(f"   ğŸ“ {info['description']}")
            print()
        
        print(f"{len(models) + 1}. ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ê²½ë¡œ")
        print(f"{len(models) + 2}. CPU ëª¨ë“œë¡œ ì‹¤í–‰ (ëŠë¦¬ì§€ë§Œ ì•ˆì „)")
        print(f"{len(models) + 3}. ë’¤ë¡œ ê°€ê¸°")
        
        while True:
            try:
                choice = input(f"\nì„ íƒí•˜ì„¸ìš” (1-{len(models) + 3}): ").strip()
                choice_num = int(choice)
                
                if 1 <= choice_num <= len(models):
                    selected_key = model_keys[choice_num - 1]
                    return 'model', selected_key
                elif choice_num == len(models) + 1:
                    return 'custom', None
                elif choice_num == len(models) + 2:
                    return 'cpu', None
                elif choice_num == len(models) + 3:
                    return 'back', None
                else:
                    print(f"âŒ 1-{len(models) + 3} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except ValueError:
                print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                return 'back', None
    
    def show_cloud_model_menu(self):
        """í´ë¼ìš°ë“œ ëª¨ë¸ ì„ íƒ ë©”ë‰´"""
        print("\n" + "="*60)
        print("â˜ï¸  Qwen Cloud API ëª¨ë¸ ì„ íƒ")
        print("="*60)
        
        # API í‚¤ í™•ì¸
        if not self.api_key or self.api_key == "your_api_key_here":
            print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì—ì„œ QWEN_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
            return 'back', None
        
        print(f"ğŸ”‘ API í‚¤: {'*' * (len(self.api_key) - 8) + self.api_key[-8:]}")
        print()
        
        # ëª¨ë¸ ëª©ë¡ í‘œì‹œ
        models = list_cloud_models()
        model_keys = list(models.keys())
        
        for i, (key, info) in enumerate(models.items(), 1):
            print(f"{i}. {info['name']}")
            print(f"   ğŸ“ {info['description']}")
            print()
        
        print(f"{len(models) + 1}. ë’¤ë¡œ ê°€ê¸°")
        
        while True:
            try:
                choice = input(f"\nì„ íƒí•˜ì„¸ìš” (1-{len(models) + 1}): ").strip()
                choice_num = int(choice)
                
                if 1 <= choice_num <= len(models):
                    selected_key = model_keys[choice_num - 1]
                    return 'model', selected_key
                elif choice_num == len(models) + 1:
                    return 'mode_select', None
                elif choice_num == len(models) + 2:
                    return 'back', None
                else:
                    print(f"âŒ 1-{len(models) + 2} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except ValueError:
                print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                return 'back', None
    
    def show_ocr_mode_menu(self):
        """ì¶”ì¶œ ëª¨ë“œ ì„ íƒ ë©”ë‰´"""
        print("\n" + "="*60)
        print("ğŸ¯ OCR ëª¨ë“œ ì„ íƒ")
        print("="*60)
        
        print("1. ì†ê·¸ë¦¼ ë„í˜• ê°ì§€ ëª¨ë“œ")
        print("   - ì›, íƒ€ì›, ì‚¬ê°í˜• ë“±ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ")
        print("   - ìŠ¤ìº”ë¬¸ì„œì—ì„œ íŠ¹ì • ì˜ì—­ë§Œ ì¸ì‹í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©")
        print("   - ì˜ˆ: ì‹œí——ì§€ì—ì„œ ì±„ì í•  ë¬¸ì œë§Œ ì¶”ì¶œ")
        print()
        print("2. í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ (ì¶”ì²œ!) ğŸ†")
        print("   - OpenCVë¡œ ë„í˜• ìœ„ì¹˜ ì°¾ê¸° + AIë¡œ ê° ì˜ì—­ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        print("   - ìµœê³  ì •í™•ë„: 12ê°œ ë„í˜• ëª¨ë‘ ì¸ì‹ ê°€ëŠ¥")
        print("   - ì¤‘ê¸° ê°œì„ : ì»´í“¨í„° ë¹„ì „ + AI ì¡°í•©")
        print()
        print("3. ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ëª¨ë“œ")
        print("   - ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ")
        print("   - ì¢Œí‘œê°’ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
        print("   - ì¼ë°˜ì ì¸ OCR ì‘ì—…ì— ì‚¬ìš©")
        print()
        print("4. ë’¤ë¡œ ê°€ê¸°")
        
        while True:
            try:
                choice = input("\nì„ íƒí•˜ì„¸ìš” (1-4): ").strip()
                
                if choice == '1':
                    return 'shape_detection'
                elif choice == '2':
                    return 'hybrid'
                elif choice == '3':
                    return 'general'
                elif choice == '4':
                    return 'back'
                else:
                    print("âŒ 1-4 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except KeyboardInterrupt:
                return 'back'
    
    def show_settings(self):
        """ì„¤ì • ì •ë³´ í‘œì‹œ"""
        print("\n" + "="*50)
        print("âš™ï¸  í˜„ì¬ ì„¤ì •")
        print("="*50)
        
        # í™˜ê²½ ë³€ìˆ˜
        print("ğŸ“ ê²½ë¡œ ì„¤ì •:")
        print(f"   ì…ë ¥ í´ë”: {os.path.abspath(self.input_dir)}")
        print(f"   ì¶œë ¥ í´ë”: {os.path.abspath(self.output_dir)}")
        
        print("\nğŸ”‘ API ì„¤ì •:")
        if self.api_key and self.api_key != "your_api_key_here":
            print(f"   API í‚¤: {'*' * (len(self.api_key) - 8) + self.api_key[-8:]}")
        else:
            print("   API í‚¤: âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        print_system_info()
        
        # ëª¨ë¸ ë§¤ë‹ˆì € ì •ë³´
        print("\nğŸ§  ëª¨ë¸ ë§¤ë‹ˆì €:")
        try:
            memory_info = get_memory_info()
            print(f"   ë¡œë“œëœ ëª¨ë¸: {memory_info['loaded_models']}/{memory_info['max_models']}")
            
            loaded_models = get_loaded_models_info()
            if loaded_models:
                print("   í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ë“¤:")
                for model_info in loaded_models:
                    status = "ğŸ”´" if model_info['is_current'] else "âšª"
                    model_name = model_info['model_id'].split('/')[-1]
                    print(f"     {status} {model_name} ({model_info['device']})")
            else:
                print("   ë¡œë“œëœ ëª¨ë¸ ì—†ìŒ")
                
            if 'gpu_memory_allocated' in memory_info:
                print(f"   GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info['gpu_memory_allocated']:.2f}GB")
        except Exception as e:
            print(f"   ëª¨ë¸ ë§¤ë‹ˆì € ì •ë³´ ì–»ê¸° ì‹¤íŒ¨: {e}")
        
        # ì…ë ¥ ì´ë¯¸ì§€ ì •ë³´
        image_files = get_image_files(self.input_dir)
        print(f"ğŸ“Š ì…ë ¥ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        if image_files:
            print("   íŒŒì¼ ëª©ë¡:")
            for img in image_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"   - {os.path.basename(img)}")
            if len(image_files) > 5:
                print(f"   ... ì™¸ {len(image_files) - 5}ê°œ")
        
        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    def handle_custom_model(self):
        """ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ê²½ë¡œ ì²˜ë¦¬"""
        print("\nì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
        print("ì˜ˆ: Qwen/Qwen2.5-VL-1.5B-Instruct")
        
        model_path = input("ëª¨ë¸ ê²½ë¡œ: ").strip()
        if not model_path:
            return None
        
        # ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ì •ë³´ ìƒì„±
        custom_info = {
            "name": f"Custom: {model_path}",
            "model_id": model_path,
            "params": "Unknown",
            "min_gpu_memory": 0,
            "recommended_gpu_memory": 0,
            "description": "ì‚¬ìš©ì ì •ì˜ ëª¨ë¸"
        }
        
        return custom_info
    
    def _run_local_with_processor(self, processor, image_files):
        """ë¡œì»¬ ëª¨ë¸ í”„ë¡œì„¸ì„œë¡œ ì§ì ‘ ì‹¤í–‰"""
        try:
            # ëª¨ë¸ ë¡œë“œ
            success, load_time = processor.load_model()
            if not success:
                print("âŒ ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            
            print(f"â±ï¸  ëª¨ë¸ ë¡œë”© ì‹œê°„: {load_time:.2f}ì´ˆ")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            success = processor.process_images(image_files, self.output_dir)
            
            if success:
                print("\nâœ… ë¡œì»¬ ëª¨ë¸ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                print("\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            processor.cleanup()
    
    def run_local_processing(self, model_info):
        """ë¡œì»¬ ëª¨ë¸ ì²˜ë¦¬ ì‹¤í–‰ - ê°œì„ ëœ ë²„ì „"""
        print(f"\nğŸš€ ë¡œì»¬ ëª¨ë¸ ì²˜ë¦¬ ì‹œì‘: {model_info['name']}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        image_files = get_image_files(self.input_dir)
        
        if not image_files:
            print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í™•ì¸ ë©”ì‹œì§€
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        
        # ëª¨ë¸ ë§¤ë‹ˆì € ìƒíƒœ í‘œì‹œ
        try:
            memory_info = get_memory_info()
            loaded_models = get_loaded_models_info()
            
            if loaded_models:
                print(f"â™¾ï¸  í˜„ì¬ ë¡œë“œëœ ëª¨ë¸: {len(loaded_models)}ê°œ")
                for model in loaded_models:
                    status = "ğŸ”´ í™œì„±" if model['is_current'] else "âšª ëŒ€ê¸°"
                    print(f"   {status} {model['model_id'].split('/')[-1]}")
            else:
                print("ğŸ†• ë¡œë“œëœ ëª¨ë¸ ì—†ìŒ - ìƒˆë¡œ ë¡œë“œë¨")
        except Exception:
            pass
        
        confirm = input("ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        
        if confirm != 'y':
            print("ì²˜ë¦¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # OCR ì²˜ë¦¬ ì‹¤í–‰ (ê°œì„ ëœ ë²„ì „)
        from local_ocr_improved import run_local_ocr
        success = run_local_ocr(model_info, image_files, self.output_dir)
        
        if success:
            print("\nâœ… ë¡œì»¬ ëª¨ë¸ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì²˜ë¦¬ í›„ ëª¨ë¸ ìƒíƒœ í‘œì‹œ
            try:
                updated_models = get_loaded_models_info()
                print(f"ğŸ§  ì²˜ë¦¬ í›„ ë¡œë“œëœ ëª¨ë¸: {len(updated_models)}ê°œ")
            except Exception:
                pass
        else:
            print("\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def open_model_management(self):
        """ëª¨ë¸ ê´€ë¦¬ ë„êµ¬ ì—´ê¸°"""
        print("\nğŸ› ï¸  ëª¨ë¸ ê´€ë¦¬ ë„êµ¬ë¥¼ ì—½ë‹ˆë‹¤...")
        
        try:
            # ëª¨ë¸ ê´€ë¦¬ ë„êµ¬ ì‹¤í–‰
            from model_management_tool import main as model_tool_main
            model_tool_main()
        except ImportError:
            print("âŒ ëª¨ë¸ ê´€ë¦¬ ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ê´€ë¦¬ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    
    def run_cloud_processing(self, model_name, ocr_mode="shape_detection"):
        """í´ë¼ìš°ë“œ API ì²˜ë¦¬ ì‹¤í–‰ - ëª¨ë“œ ì§€ì›"""
        print(f"\nğŸŒ í´ë¼ìš°ë“œ API ì²˜ë¦¬ ì‹œì‘: {model_name}")
        print(f"ğŸ¯ OCR ëª¨ë“œ: {ocr_mode}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        image_files = get_image_files(self.input_dir)
        
        if not image_files:
            print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ëª¨ë“œë³„ ì„¤ëª…
        if ocr_mode == "shape_detection":
            mode_desc = "ì†ê·¸ë¦¼ ë„í˜•ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"
        elif ocr_mode == "hybrid":
            mode_desc = "í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: OpenCV ë„í˜• ê°ì§€ + AI í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìµœê³  ì •í™•ë„)"
        else:
            mode_desc = "ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¢Œí‘œê°’ ì˜¤ë¥˜ ë°©ì§€ í”„ë¡¬í”„íŠ¸ ì ìš©)"
        
        # í™•ì¸ ë©”ì‹œì§€
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        print(f"ğŸ’° ì˜ˆìƒ API í˜¸ì¶œ ìˆ˜: {len(image_files)}íšŒ")
        print(f"ğŸ¯ ì¶”ì¶œ ëª¨ë“œ: {mode_desc}")
        
        confirm = input("ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        
        if confirm != 'y':
            print("ì²˜ë¦¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # OCR ì²˜ë¦¬ ì‹¤í–‰
        success = run_cloud_ocr(self.api_key, model_name, image_files, self.output_dir, ocr_mode)
        
        if success:
            print("\nâœ… í´ë¼ìš°ë“œ API ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print("ğŸš€ OCR ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬ ì‹œì‘")
        
        while True:
            choice = self.show_main_menu()
            
            if choice == '1':  # ë¡œì»¬ ëª¨ë¸
                while True:
                    action, data = self.show_local_model_menu()
                    
                    if action == 'back':
                        break
                    elif action == 'model':
                        model_info = get_model_info(data, "local")
                        self.run_local_processing(model_info)
                        break
                    elif action == 'custom':
                        model_info = self.handle_custom_model()
                        if model_info:
                            self.run_local_processing(model_info)
                        break
                    elif action == 'cpu':
                        # CPU ë¡œ ì‹¤í–‰í•  ëª¨ë¸ ì„ íƒ
                        print("\nâš ï¸  CPU ëª¨ë“œ ì„¤ì •")
                        print("â³ CPU ëª¨ë“œëŠ” ë§¤ìš° ëŠë¦½ë‹ˆë‹¤. ê·¸ë˜ë„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                        confirm = input("ê³„ì† (y/N): ").strip().lower()
                        if confirm == 'y':
                            # ê¸°ë³¸ 3B ëª¨ë¸ì„ CPUë¡œ ì‹¤í–‰
                            model_info = get_model_info("qwen2.5-vl-3b", "local")
                            # ë””ë°”ì´ìŠ¤ë¥¼ CPUë¡œ ê°•ì œ ì„¤ì •
                            processor = LocalOCRProcessor(model_info["model_id"], device="cpu")
                            image_files = get_image_files(self.input_dir)
                            if image_files:
                                print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€: {len(image_files)}ê°œ")
                                confirm2 = input("ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
                                if confirm2 == 'y':
                                    self._run_local_with_processor(processor, image_files)
                        break
            
            elif choice == '2':  # í´ë¼ìš°ë“œ API
                current_mode = "hybrid"  # ê¸°ë³¸ ëª¨ë“œë¥¼ í•˜ì´ë¸Œë¦¬ë“œë¡œ ë³€ê²½
                
                while True:
                    action, data = self.show_cloud_model_menu()
                    
                    if action == 'back':
                        break
                    elif action == 'model':
                        self.run_cloud_processing(data, current_mode)
                        break
                    elif action == 'mode_select':
                        # ëª¨ë“œ ì„ íƒ ë©”ë‰´
                        selected_mode = self.show_ocr_mode_menu()
                        if selected_mode != 'back':
                            current_mode = selected_mode
                            print(f"âœ… OCR ëª¨ë“œê°€ '{current_mode}'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            input("ë‹¤ìŒìœ¼ë¡œ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
            
            elif choice == '3':  # ì„¤ì • í™•ì¸
                self.show_settings()
            
            elif choice == '4':  # ëª¨ë¸ ê´€ë¦¬ ë„êµ¬
                self.open_model_management()
            
            elif choice == '5':  # ì¢…ë£Œ
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        interface = OCRTestInterface()
        interface.run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main()
