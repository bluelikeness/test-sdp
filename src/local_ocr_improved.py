"""
ê°œì„ ëœ ë¡œì»¬ ëª¨ë¸ OCR ì²˜ë¦¬ - ëª¨ë¸ ì¬ì‚¬ìš©
"""

import torch
from PIL import Image
import os
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

from utils import create_output_directory, draw_text_on_image, save_text_result, measure_time
from model_manager import get_model_manager

class LocalOCRProcessor:
    def __init__(self, model_id, device="auto"):
        self.model_id = model_id
        self.device = device
        self.model_manager = get_model_manager()
        self.model = None
        self.processor = None
        self.actual_device = None
        
    def ensure_model_loaded(self):
        """ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¡œë“œ"""
        try:
            self.model, self.processor, self.actual_device = self.model_manager.get_model(
                self.model_id, 
                self.device
            )
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def process_image(self, image_path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        if not self.ensure_model_loaded():
            return "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
        
        try:
            if self.actual_device == "cpu":
                print(f"â³ CPU ëª¨ë“œë¡œ ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(image_path).convert('RGB')
            
            # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸
            prompt = "Find all text that has been manually circled with oval/elliptical pen marks and extract only those text items. Output only the results without any explanation or additional text."

            # Qwen2-VL ì „ìš© ì…ë ¥ í˜•ì‹
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": image},
                        {"type": "text", "text": prompt}
                    ]
                }
            ]
            
            # í”„ë¡œì„¸ì„œë¡œ ì…ë ¥ ì²˜ë¦¬
            text = self.processor.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True
            )
            
            inputs = self.processor(
                text=[text],
                images=[image], 
                padding=True,
                return_tensors="pt"
            )
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            if self.actual_device == "cuda":
                inputs = inputs.to("cuda")
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=512,
                    do_sample=False,
                    pad_token_id=self.processor.tokenizer.eos_token_id
                )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            result = output_text.strip()
            
            if self.actual_device == "cpu":
                print(f"âœ… CPU ì²˜ë¦¬ ì™„ë£Œ: {len(result)}ì ì¶”ì¶œ")
            
            return result
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return error_msg
    
    @measure_time
    def process_images(self, image_files, output_base_dir):
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ - ëª¨ë¸ ì¬ì‚¬ìš©"""
        if not self.ensure_model_loaded():
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        model_name = self.model_id.split('/')[-1]
        output_dir = create_output_directory(output_base_dir, f"local_{model_name}")
        
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ í´ë”: {output_dir}")
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}")
        print(f"ğŸ§  ì‚¬ìš© ëª¨ë¸: {self.model_id}")
        print(f"ğŸ’¾ ë””ë°”ì´ìŠ¤: {self.actual_device}")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ
        memory_info = self.model_manager.get_memory_usage()
        print(f"ğŸ“ˆ í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ìˆ˜: {memory_info['loaded_models']}/{memory_info['max_models']}")
        
        total_time = 0
        successful_count = 0
        results = []
        
        # ì§„í–‰ë¥  í‘œì‹œ
        with tqdm(total=len(image_files), desc="ì´ë¯¸ì§€ ì²˜ë¦¬ì¤‘") as pbar:
            for i, image_path in enumerate(image_files):
                filename = os.path.basename(image_path)
                pbar.set_postfix({"í˜„ì¬": filename})
                
                try:
                    # OCR ì²˜ë¦¬ (ì‹œê°„ ì¸¡ì •)
                    start_time = time.time()
                    result_text = self.process_image(image_path)
                    process_time = time.time() - start_time
                    total_time += process_time
                    
                    # ê²°ê³¼ ì €ì¥
                    if result_text and not result_text.startswith("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨") and not result_text.startswith("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜"):
                        successful_count += 1
                        
                        # í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
                        text_file = save_text_result(result_text, output_dir, filename)
                        
                        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
                        base_name = os.path.splitext(filename)[0]
                        output_image_path = os.path.join(output_dir, f"{base_name}_result.png")
                        success = draw_text_on_image(image_path, result_text, output_image_path)
                        
                        # í…ìŠ¤íŠ¸ ì¢Œí‘œ ë§¤í•‘ ì´ë¯¸ì§€ ìƒì„±
                        try:
                            from text_coordinate_mapping import create_text_coordinate_mapping
                            coord_success = create_text_coordinate_mapping(
                                image_path, result_text, output_dir, method="auto"
                            )
                            if coord_success:
                                print(f"ğŸ¯ ì¢Œí‘œ ë§¤í•‘ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
                        except Exception as coord_error:
                            print(f"âš ï¸  ì¢Œí‘œ ë§¤í•‘ ì˜¤ë¥˜: {coord_error}")
                        
                        results.append({
                            'file': filename,
                            'success': True,
                            'text_length': len(result_text),
                            'time': process_time
                        })
                        
                        print(f"âœ… {filename}: {len(result_text)}ì ì¶”ì¶œ ({process_time:.2f}ì´ˆ)")
                        
                    else:
                        print(f"âš ï¸  ì‹¤íŒ¨: {filename} - {result_text}")
                        results.append({
                            'file': filename,
                            'success': False,
                            'error': result_text,
                            'time': process_time
                        })
                
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜: {filename} - {str(e)}")
                    results.append({
                        'file': filename,
                        'success': False,
                        'error': str(e),
                        'time': 0
                    })
                
                pbar.update(1)
        
        # ê²°ê³¼ ìš”ì•½ ì €ì¥
        summary_path = os.path.join(output_dir, "summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"=== ë¡œì»¬ ëª¨ë¸ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ===\n")
            f.write(f"ëª¨ë¸: {self.model_id}\n")
            f.write(f"ë””ë°”ì´ìŠ¤: {self.actual_device}\n")
            f.write(f"ì„±ê³µ: {successful_count}/{len(image_files)} ì´ë¯¸ì§€\n")
            f.write(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ\n")
            f.write(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(image_files):.2f}ì´ˆ/ì´ë¯¸ì§€\n\n")
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            f.write(f"=== ë©”ëª¨ë¦¬ ì‚¬ìš© ì •ë³´ ===\n")
            memory_info = self.model_manager.get_memory_usage()
            for key, value in memory_info.items():
                f.write(f"{key}: {value}\n")
            f.write("\n")
            
            for result in results:
                f.write(f"íŒŒì¼: {result['file']}\n")
                f.write(f"ì„±ê³µ: {'ì˜ˆ' if result['success'] else 'ì•„ë‹ˆì˜¤'}\n")
                if result['success']:
                    f.write(f"ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´: {result['text_length']}ì\n")
                else:
                    f.write(f"ì˜¤ë¥˜: {result.get('error', 'Unknown')}\n")
                f.write(f"ì²˜ë¦¬ ì‹œê°„: {result['time']:.2f}ì´ˆ\n")
                f.write("-" * 30 + "\n")
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n=== ì²˜ë¦¬ ì™„ë£Œ ===")
        print(f"ì„±ê³µ: {successful_count}/{len(image_files)} ì´ë¯¸ì§€")
        print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(image_files):.2f}ì´ˆ/ì´ë¯¸ì§€")
        print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        
        # ëª¨ë¸ ì¬ì‚¬ìš© ìƒíƒœ í‘œì‹œ
        loaded_models = self.model_manager.list_loaded_models()
        print(f"ğŸ”„ ëª¨ë¸ ìƒíƒœ: {len(loaded_models)}ê°œ ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë¨")
        
        return True
    
    def cleanup(self):
        """ëª¨ë¸ì€ ë§¤ë‹ˆì €ê°€ ê´€ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì°¸ì¡°ë§Œ ì •ë¦¬"""
        self.model = None
        self.processor = None
        self.actual_device = None
        print("ğŸ”— ëª¨ë¸ ì°¸ì¡° ì •ë¦¬ ì™„ë£Œ (ëª¨ë¸ì€ ë§¤ë‹ˆì €ê°€ ìœ ì§€)")


def run_local_ocr(model_info, image_files, output_dir):
    """ë¡œì»¬ OCR ì‹¤í–‰ í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „"""
    processor = LocalOCRProcessor(model_info["model_id"])
    
    try:
        # ëª¨ë¸ ë¡œë“œ (ë§¤ë‹ˆì €ë¥¼ í†µí•´)
        if not processor.ensure_model_loaded():
            return False
        
        print(f"â™»ï¸  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: {model_info['name']}")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        success, process_time = processor.process_images(image_files, output_dir)
        
        print(f"â±ï¸  ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        
        return success
        
    finally:
        # ëª¨ë¸ì€ ë§¤ë‹ˆì €ê°€ ê´€ë¦¬í•˜ë¯€ë¡œ ì°¸ì¡°ë§Œ ì •ë¦¬
        processor.cleanup()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("ğŸ§ª ê°œì„ ëœ ë¡œì»¬ OCR í…ŒìŠ¤íŠ¸")
    
    # ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸
    print("ë©”ëª¨ë¦¬ ì •ë³´:", get_memory_info())
    
    # ë¡œë“œëœ ëª¨ë¸ í™•ì¸
    print("ë¡œë“œëœ ëª¨ë¸ë“¤:", get_loaded_models_info())


# ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤
def get_loaded_models_info():
    """í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    manager = get_model_manager()
    return manager.list_loaded_models()

def clear_all_models():
    """ëª¨ë“  ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì—ì„œ ì •ë¦¬"""
    manager = get_model_manager()
    manager.clear_all_models()

def get_memory_info():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜"""
    manager = get_model_manager()
    return manager.get_memory_usage()

def run_local_ocr(model_info, image_files, output_dir):
    """ë¡œì»¬ OCR ì‹¤í–‰ í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „"""
    processor = LocalOCRProcessor(model_info["model_id"])
    
    try:
        # ëª¨ë¸ ë¡œë“œ (ë§¤ë‹ˆì €ë¥¼ í†µí•´)
        if not processor.ensure_model_loaded():
            return False
        
        print(f"â™¾ï¸  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: {model_info['name']}")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        success, process_time = processor.process_images(image_files, output_dir)
        
        print(f"â±ï¸  ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        
        return success
        
    finally:
        # ëª¨ë¸ì€ ë§¤ë‹ˆì €ê°€ ê´€ë¦¬í•˜ë¯€ë¡œ ì°¸ì¡°ë§Œ ì •ë¦¬
        processor.cleanup()
